{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text classification is the automatic process of assigning predefined categories to unstructured text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we read our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv(r\"C:\\Users\\Bhavika_2\\Downloads\\SPAM text message 20170820 - Data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the first 5 rows of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change category 1 or 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data[\"Category\"] = [1 if each == \"spam\" else 0 for each in data[\"Category\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                                            Message\n",
       "0         0  Go until jurong point, crazy.. Available only ...\n",
       "1         0                      Ok lar... Joking wif u oni...\n",
       "2         1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3         0  U dun say so early hor... U c already then say...\n",
       "4         0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose 1 row and we throw punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A RegEx or Regular Expression is a sequence of characters that forms a search pattern. RegEx can be used to check if a string contains the specified search pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "nlp_data = str(data.iloc[2,:])\n",
    "nlp_data = re.sub(\"[^a-zA-Z]\",\" \",nlp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natural language processing (NLP) is an area of computer science and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.\n",
    "\n",
    "Normalization in NLP is a process that converts a list of words to a more uniform sequence. This is useful in preparing text for later processing. ... Understand that the normalization process might also compromise an NLP task. Converting to lowercase letters can decrease the reliability of searches when the case is important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After return lower case\n",
    "nlp_data = nlp_data.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Natural Language Toolkit (NLTK) is a platform used for building Python programs that work with human language data for applying in statistical natural language processing (NLP). It contains text processing libraries for tokenization, parsing, classification, stemming, tagging and semantic reasoning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Bhavika_2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Bhavika_2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing means splitting your text into minimal meaningful units. It is a mandatory step before any kind of processing. The basic tokenizer (like in NLTK) will split your text into sentences and your sentences into typographic tokens.\n",
    "\n",
    "NLTK provides a function called word_tokenize() for splitting strings into tokens (nominally words). It splits tokens based on white space and punctuation. For example, commas and periods are taken as separate tokens. Contractions are split apart (e.g. “What's” becomes “What” “'s“)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have two choice we can use split methot or tokenize\n",
    "import nltk as nlp\n",
    "nlp_data = nlp.word_tokenize(nlp_data)\n",
    "#nlp_data = nlp_data.split() or we can do so"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization is the process of grouping together the different inflected forms of a word so they can be analysed as a single item. Text preprocessing includes both Stemming as well as Lemmatization. Many times people find these two terms confusing. Some treat these two as same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have to find word root\n",
    "lemma = nlp.WordNetLemmatizer()\n",
    "nlp_data = [lemma.lemmatize(word) for word in nlp_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We join our data\n",
    "nlp_data = \" \".join(nlp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "description_list = []\n",
    "for description in data[\"Message\"]:\n",
    "    description = re.sub(\"[^a-zA-Z]\",\" \",description)\n",
    "    description = description.lower()   # buyuk harftan kucuk harfe cevirme\n",
    "    description = nlp.word_tokenize(description)\n",
    "    #description = [ word for word in description if not word in set(stopwords.words(\"english\"))]\n",
    "    lemma = nlp.WordNetLemmatizer()\n",
    "    description = [ lemma.lemmatize(word) for word in description]\n",
    "    description = \" \".join(description)\n",
    "    description_list.append(description) #we hide all word one section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CountVectorizer provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words, but also to encode new documents using that vocabulary. You can use it as follows:  Call the transform() function on one or more documents as needed to encode each as a vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop Words: A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) that a search engine has been programmed to ignore, both when indexing entries for searching and when retrieving them as the result of a search query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the most using 3000 words: ['aah', 'aathi', 'abi', 'ability', 'abiola', 'abj', 'able', 'absolutly', 'abt', 'abta', 'aburo', 'ac', 'academic', 'acc', 'accept', 'access', 'accident', 'accidentally', 'accordingly', 'account', 'ache', 'acl', 'aco', 'acted', 'acting', 'action', 'activate', 'active', 'activity', 'actor', 'actual', 'actually', 'ad', 'adam', 'add', 'addamsfa', 'added', 'addicted', 'addie', 'address', 'admin', 'administrator', 'admirer', 'admit', 'adore', 'adoring', 'adult', 'advance', 'adventure', 'advice', 'advise', 'ae', 'aeronautics', 'aeroplane', 'affair', 'affection', 'afraid', 'aft', 'afternoon', 'aftr', 'ag', 'agalla', 'age', 'agent', 'ago', 'agree', 'ah', 'aha', 'ahead', 'ahmad', 'aid', 'aight', 'ain', 'aint', 'air', 'airport', 'airtel', 'aiya', 'aiyah', 'aiyar', 'aiyo', 'aj', 'aka', 'al', 'alaipayuthe', 'album', 'alcohol', 'alert', 'alex', 'alfie', 'algarve', 'ali', 'alive', 'allah', 'allow', 'allowed', 'alright', 'alrite', 'alwys', 'amazing', 'american', 'amp', 'amt', 'amused', 'amy', 'andros', 'angry', 'animation', 'anna', 'annie', 'anniversary', 'announcement', 'annoying', 'anot', 'ansr', 'answer', 'answered', 'answering', 'anthony', 'anti', 'anybody', 'anymore', 'anythin', 'anytime', 'anyways', 'aom', 'apart', 'apartment', 'apo', 'apologise', 'app', 'apparently', 'apple', 'applebees', 'application', 'apply', 'appointment', 'appreciate', 'appreciated', 'approx', 'apps', 'appt', 'april', 'aproach', 'ar', 'arcade', 'ard', 'area', 'aren', 'arent', 'argh', 'argue', 'argument', 'arm', 'armand', 'arng', 'arrange', 'arrested', 'arrive', 'arsenal', 'art', 'arun', 'asap', 'ashley', 'ask', 'askd', 'asked', 'askin', 'asking', 'asks', 'asleep', 'asp', 'assume', 'ate', 'atlanta', 'atlast', 'atm', 'attached', 'attempt', 'attend', 'auction', 'audition', 'audrey', 'august', 'aunt', 'aunty', 'auto', 'av', 'available', 'avatar', 'ave', 'avent', 'avoid', 'avoiding', 'await', 'awaiting', 'awake', 'award', 'awarded', 'away', 'awesome', 'aww', 'ayn', 'ba', 'babe', 'baby', 'bad', 'bag', 'bahamas', 'bak', 'balance', 'ball', 'bang', 'bank', 'bar', 'barely', 'base', 'basic', 'basically', 'bat', 'batch', 'bath', 'bathe', 'bathing', 'battery', 'battle', 'bay', 'bb', 'bbd', 'bc', 'bck', 'bcm', 'bcoz', 'bcums', 'bday', 'bear', 'beautiful', 'beauty', 'bec', 'becoz', 'bed', 'bedrm', 'bedroom', 'beer', 'befor', 'beg', 'begging', 'begin', 'behave', 'bein', 'believe', 'belive', 'bell', 'belly', 'belovd', 'beloved', 'ben', 'beneath', 'beneficiary', 'benefit', 'best', 'bet', 'better', 'beware', 'bf', 'bhaji', 'bid', 'big', 'bigger', 'biggest', 'billed', 'billion', 'bin', 'biola', 'bird', 'birla', 'birth', 'birthdate', 'birthday', 'bishan', 'bit', 'bitch', 'bite', 'biz', 'bk', 'black', 'blackberry', 'blah', 'blake', 'blame', 'blank', 'blanket', 'bleh', 'bless', 'blessed', 'blessing', 'blind', 'block', 'bloke', 'blonde', 'bloo', 'blood', 'bloody', 'bloomberg', 'blow', 'blu', 'blue', 'bluetooth', 'bluff', 'blur', 'bmw', 'boat', 'body', 'bold', 'bone', 'bonus', 'boo', 'book', 'booked', 'booking', 'boost', 'booty', 'bootydelious', 'bored', 'borin', 'boring', 'born', 'borrow', 'bos', 'boston', 'bother', 'bottle', 'bought', 'bout', 'bowl', 'box', 'boy', 'boye', 'boyfriend', 'boytoy', 'bp', 'brah', 'brain', 'brand', 'brandy', 'bray', 'bread', 'break', 'breath', 'breathe', 'brief', 'bright', 'brilliant', 'bring', 'bringing', 'brings', 'bristol', 'british', 'britney', 'bro', 'broad', 'broke', 'broken', 'bros', 'brothas', 'brother', 'brought', 'brownie', 'bruce', 'bruv', 'bslvyl', 'bstfrnd', 'bt', 'btw', 'buck', 'bud', 'buddy', 'budget', 'buff', 'buffet', 'bugis', 'build', 'building', 'bulb', 'bun', 'burger', 'burn', 'burning', 'bus', 'business', 'busy', 'butt', 'buy', 'buyer', 'buying', 'buzy', 'buzz', 'bx', 'bye', 'cabin', 'cafe', 'cake', 'cal', 'calculation', 'cali', 'calicut', 'california', 'callback', 'callcost', 'calld', 'called', 'caller', 'callertune', 'callfreefone', 'callin', 'calling', 'calm', 'cam', 'camcorder', 'came', 'camera', 'campus', 'canada', 'canal', 'canary', 'cancel', 'cancelled', 'cancer', 'cann', 'capital', 'cappuccino', 'captain', 'car', 'card', 'cardiff', 'care', 'cared', 'career', 'careful', 'carefully', 'caring', 'carlos', 'caroline', 'carry', 'cartoon', 'case', 'cash', 'cashbin', 'cashto', 'castor', 'cat', 'catch', 'catching', 'caught', 'cause', 'causing', 'cbe', 'cc', 'cd', 'cdgt', 'celeb', 'celebrate', 'celebration', 'cell', 'center', 'centre', 'certainly', 'ch', 'cha', 'chain', 'challenge', 'chance', 'change', 'changed', 'channel', 'character', 'charge', 'charged', 'charity', 'charles', 'chart', 'chase', 'chasing', 'chat', 'chatting', 'cheap', 'cheaper', 'cheat', 'cheating', 'chechi', 'check', 'checked', 'checking', 'cheer', 'chennai', 'chicken', 'chikku', 'child', 'childish', 'chill', 'chillin', 'china', 'chinese', 'choice', 'choose', 'chosen', 'christmas', 'church', 'cine', 'cinema', 'citizen', 'city', 'claim', 'claire', 'class', 'clean', 'cleaning', 'clear', 'cleared', 'click', 'clock', 'clos', 'close', 'closed', 'closer', 'club', 'cm', 'cn', 'cock', 'code', 'coffee', 'coin', 'cold', 'colleague', 'collect', 'collected', 'collecting', 'collection', 'college', 'colour', 'com', 'come', 'comedy', 'comin', 'coming', 'common', 'community', 'comp', 'company', 'competition', 'complete', 'completely', 'complimentary', 'computer', 'comuk', 'concentrate', 'concert', 'condition', 'confidence', 'confirm', 'confirmed', 'congrats', 'congratulation', 'connect', 'connection', 'considering', 'constantly', 'contact', 'contacted', 'content', 'contract', 'convey', 'cook', 'cooking', 'cool', 'copy', 'cornwall', 'correct', 'cost', 'costa', 'couldn', 'count', 'country', 'couple', 'course', 'cover', 'coz', 'cr', 'crab', 'crack', 'cramp', 'crave', 'crazy', 'cream', 'created', 'credit', 'credited', 'creepy', 'cricketer', 'crisis', 'crore', 'cross', 'croydon', 'cruise', 'csbcm', 'csh', 'ctxt', 'cud', 'cuddle', 'cuddling', 'cum', 'cup', 'curious', 'current', 'currently', 'curry', 'cust', 'custcare', 'custom', 'customer', 'cut', 'cute', 'cutefrnd', 'cuz', 'cw', 'da', 'dad', 'daddy', 'dai', 'daily', 'damn', 'dare', 'dark', 'darlin', 'darling', 'darren', 'dat', 'date', 'datebox', 'dating', 'datz', 'dave', 'day', 'dead', 'deal', 'dear', 'dearer', 'dearly', 'death', 'december', 'decide', 'decided', 'decimal', 'decision', 'deep', 'def', 'definitely', 'del', 'deleted', 'deliver', 'delivered', 'deliveredtomorrow', 'delivery', 'dem', 'den', 'depends', 'derek', 'dey', 'di', 'diamond', 'dick', 'dictionary', 'did', 'didn', 'didnt', 'die', 'died', 'diet', 'diff', 'difference', 'different', 'difficult', 'dificult', 'digital', 'dignity', 'din', 'dinner', 'dint', 'direct', 'directly', 'dirty', 'dis', 'discount', 'discus', 'dislike', 'display', 'distance', 'disturb', 'dload', 'dnt', 'doc', 'doctor', 'doe', 'doesn', 'doesnt', 'dog', 'dogging', 'doggy', 'doin', 'doing', 'dollar', 'don', 'dont', 'door', 'dot', 'double', 'download', 'downloads', 'draw', 'dream', 'dress', 'dressed', 'dresser', 'drink', 'drinking', 'drive', 'drivin', 'driving', 'drop', 'dropped', 'drug', 'drunk', 'dry', 'dsn', 'dubsack', 'dude', 'dun', 'dunno', 'dvd', 'ear', 'earlier', 'early', 'earth', 'easier', 'easy', 'eat', 'eaten', 'eatin', 'eating', 'ec', 'eerie', 'effect', 'egg', 'eh', 'em', 'email', 'embarassed', 'end', 'ended', 'ending', 'enemy', 'energy', 'eng', 'england', 'english', 'enjoy', 'enjoyed', 'enter', 'entered', 'entitled', 'entry', 'enuff', 'envelope', 'er', 'erm', 'error', 'escape', 'ese', 'especially', 'esplanade', 'essential', 'euro', 'eve', 'evening', 'event', 'everybody', 'evn', 'evng', 'evry', 'ex', 'exact', 'exactly', 'exam', 'excellent', 'exciting', 'excuse', 'exe', 'executive', 'exhausted', 'expect', 'expecting', 'expensive', 'experience', 'expires', 'explain', 'express', 'extra', 'eye', 'fa', 'face', 'facebook', 'fact', 'failed', 'fair', 'fall', 'family', 'fan', 'fancy', 'fantastic', 'fantasy', 'far', 'farm', 'fast', 'faster', 'fat', 'father', 'fathima', 'fault', 'fave', 'favor', 'favour', 'favourite', 'fb', 'fear', 'feb', 'february', 'fee', 'feel', 'feelin', 'feeling', 'fell', 'felt', 'female', 'fetch', 'fever', 'fight', 'fighting', 'fightng', 'figure', 'file', 'film', 'final', 'finally', 'fine', 'finger', 'finish', 'finished', 'finishing', 'fish', 'fit', 'fix', 'fixed', 'fl', 'flag', 'flaked', 'flash', 'flat', 'flight', 'flirt', 'floor', 'flower', 'fly', 'fml', 'follow', 'followed', 'following', 'fone', 'food', 'fool', 'foot', 'football', 'footprint', 'force', 'foreign', 'forever', 'forevr', 'forget', 'forgot', 'form', 'forum', 'forward', 'forwarded', 'fr', 'fran', 'freak', 'free', 'freefone', 'freemsg', 'freephone', 'freezing', 'fren', 'frens', 'fri', 'friday', 'friend', 'friendship', 'frm', 'frnd', 'frnds', 'frndship', 'frog', 'fromm', 'frying', 'fuck', 'fucked', 'fuckin', 'fucking', 'ful', 'fullonsms', 'fun', 'function', 'funeral', 'funk', 'funky', 'funny', 'furniture', 'future', 'fwd', 'fyi', 'ga', 'gain', 'gal', 'galileo', 'game', 'gamestar', 'ganesh', 'gang', 'gap', 'garage', 'garbage', 'garden', 'gardener', 'gary', 'gas', 'gastroenteritis', 'gautham', 'gave', 'gay', 'gaytextbuddy', 'gb', 'gbp', 'gd', 'ge', 'gee', 'geeee', 'geeeee', 'gender', 'generally', 'genius', 'gent', 'gentle', 'gentleman', 'gently', 'genuine', 'george', 'germany', 'getstop', 'gettin', 'getting', 'getzed', 'geva', 'gf', 'ghost', 'gift', 'gim', 'girl', 'girlfrnd', 'giv', 'given', 'giving', 'glad', 'gm', 'gn', 'goal', 'god', 'goin', 'going', 'gon', 'gona', 'gone', 'good', 'goodmorning', 'goodnight', 'goodnite', 'google', 'gorgeous', 'gossip', 'got', 'goto', 'govt', 'gr', 'grahmbell', 'gram', 'grand', 'gravity', 'great', 'green', 'greet', 'greeting', 'grin', 'grl', 'ground', 'group', 'gt', 'guaranteed', 'gud', 'gudnite', 'guess', 'guide', 'guilty', 'guy', 'gym', 'ha', 'haf', 'haha', 'hahaha', 'hai', 'hair', 'haiz', 'half', 'halloween', 'ham', 'hand', 'handed', 'handle', 'handset', 'hanging', 'happen', 'happend', 'happened', 'happening', 'happens', 'happiness', 'happy', 'hard', 'hardcore', 'harry', 'hasn', 'hate', 'hav', 'haven', 'havent', 'havin', 'having', 'havnt', 'head', 'headache', 'hear', 'heard', 'heart', 'heavy', 'hee', 'height', 'helen', 'hell', 'hella', 'hello', 'help', 'hey', 'hg', 'hi', 'hide', 'high', 'hill', 'hint', 'hip', 'history', 'hit', 'hiya', 'hl', 'hmm', 'hmmm', 'hmv', 'ho', 'hold', 'holder', 'holding', 'holiday', 'holla', 'hols', 'home', 'homeowner', 'hon', 'honey', 'honeybee', 'hook', 'hop', 'hope', 'hopefully', 'hoping', 'horny', 'horrible', 'hospital', 'hostel', 'hot', 'hotel', 'hour', 'house', 'hows', 'howz', 'hp', 'hr', 'http', 'hubby', 'hug', 'huh', 'hun', 'hungry', 'hunny', 'hurry', 'hurt', 'husband', 'hv', 'hw', 'iam', 'ibhltd', 'ibiza', 'ic', 'ice', 'id', 'idea', 'identifier', 'idiot', 'idk', 'ignore', 'ikea', 'il', 'ill', 'im', 'imagine', 'imma', 'immediately', 'important', 'impossible', 'inch', 'incident', 'include', 'including', 'inclusive', 'india', 'indian', 'infernal', 'info', 'inform', 'information', 'informed', 'inning', 'insha', 'inside', 'instantly', 'instead', 'instituitions', 'instruction', 'insurance', 'intelligent', 'intention', 'interested', 'interesting', 'interflora', 'internet', 'interview', 'intro', 'invader', 'invest', 'invite', 'invited', 'inviting', 'invnted', 'iouri', 'ip', 'ipad', 'ipod', 'iq', 'irritates', 'irritating', 'iscoming', 'ish', 'island', 'isn', 'isnt', 'issue', 'italian', 'itcould', 'item', 'itwhichturnedinto', 'itz', 'ive', 'iz', 'izzit', 'ja', 'jacket', 'jackpot', 'jada', 'james', 'jamster', 'jan', 'jane', 'january', 'japanese', 'jas', 'jason', 'java', 'jay', 'jaya', 'jazz', 'jd', 'jealous', 'jean', 'jen', 'jenny', 'jerry', 'jess', 'jesus', 'jhl', 'jia', 'jiayin', 'jiu', 'jo', 'joanna', 'job', 'jogging', 'john', 'join', 'joined', 'joining', 'joke', 'jokin', 'joking', 'jolly', 'jolt', 'jordan', 'journey', 'joy', 'jsco', 'jst', 'jstfrnd', 'jsut', 'juan', 'juicy', 'july', 'june', 'jus', 'just', 'juz', 'kadeem', 'kaiez', 'kallis', 'kano', 'kappa', 'karaoke', 'kate', 'kavalan', 'kay', 'kb', 'ke', 'keeping', 'kegger', 'kent', 'kept', 'kerala', 'keralacircle', 'kettoda', 'key', 'kg', 'kick', 'kickoff', 'kid', 'kidding', 'kidz', 'kill', 'killed', 'killing', 'kind', 'kinda', 'kindly', 'king', 'kiosk', 'kiss', 'kl', 'knackered', 'knee', 'knew', 'knock', 'know', 'knowing', 'knw', 'konw', 'kothi', 'kr', 'kudi', 'kusruthi', 'kz', 'la', 'lab', 'lac', 'lady', 'lag', 'laid', 'land', 'landline', 'lane', 'langport', 'language', 'laptop', 'lar', 'largest', 'late', 'lately', 'later', 'latest', 'latr', 'laugh', 'laughed', 'laughing', 'laundry', 'law', 'lay', 'lazy', 'lccltd', 'ldew', 'ldn', 'ldnw', 'le', 'lead', 'leaf', 'learn', 'leave', 'leaving', 'lect', 'lecture', 'left', 'leg', 'legal', 'leh', 'lei', 'lem', 'length', 'leona', 'lesson', 'let', 'letter', 'lf', 'liao', 'lib', 'library', 'lick', 'lido', 'lie', 'life', 'lifetime', 'lifpartnr', 'lift', 'light', 'lik', 'like', 'liked', 'likely', 'lil', 'lily', 'limit', 'limiting', 'line', 'linerental', 'link', 'lion', 'lionm', 'lionp', 'lip', 'list', 'listen', 'listening', 'literally', 'little', 'live', 'lived', 'liverpool', 'living', 'lk', 'll', 'lmao', 'lo', 'load', 'loan', 'local', 'location', 'lock', 'log', 'login', 'logo', 'lol', 'london', 'lonely', 'long', 'longer', 'look', 'lookatme', 'looked', 'lookin', 'looking', 'loose', 'lor', 'lose', 'loses', 'losing', 'loss', 'lost', 'lot', 'lotr', 'lotta', 'lou', 'loud', 'lounge', 'lousy', 'lov', 'lovable', 'love', 'loved', 'lovejen', 'lovely', 'loveme', 'lover', 'loverboy', 'loving', 'lovingly', 'low', 'lower', 'loxahatchee', 'loyal', 'loyalty', 'lp', 'lst', 'lt', 'lttrs', 'luck', 'lucky', 'lucozade', 'lucy', 'lunch', 'lush', 'luv', 'luvs', 'lux', 'luxury', 'lv', 'lvblefrnd', 'lyf', 'lyfu', 'lyk', 'ma', 'maangalyam', 'mac', 'machan', 'macho', 'mad', 'madam', 'mag', 'maga', 'magical', 'mah', 'mahal', 'maid', 'mail', 'mailbox', 'main', 'maintain', 'major', 'make', 'makin', 'making', 'malaria', 'male', 'mall', 'man', 'manage', 'managed', 'management', 'manda', 'mandan', 'maneesha', 'map', 'march', 'margaret', 'mark', 'market', 'marriage', 'married', 'marrow', 'marry', 'massage', 'massive', 'master', 'match', 'mate', 'math', 'mathematics', 'matrix', 'matter', 'matured', 'maturity', 'max', 'maximize', 'mayb', 'maybe', 'mb', 'mca', 'mcat', 'meal', 'mean', 'meaning', 'meant', 'measure', 'med', 'medical', 'medicine', 'meet', 'meetin', 'meeting', 'mega', 'meh', 'mei', 'mel', 'melle', 'melt', 'member', 'membership', 'memory', 'men', 'mental', 'menu', 'meow', 'merry', 'mesages', 'mess', 'message', 'messaged', 'messaging', 'messenger', 'messy', 'met', 'mi', 'mid', 'middle', 'midnight', 'mids', 'mila', 'mile', 'milk', 'million', 'min', 'mind', 'mini', 'minimum', 'minmobsmorelkpobox', 'minmoremobsemspobox', 'minnaminunginte', 'minor', 'minute', 'minuts', 'miracle', 'misbehaved', 'miserable', 'miss', 'missed', 'missin', 'missing', 'mistake', 'mite', 'mitsake', 'mix', 'mk', 'ml', 'mm', 'mmm', 'mmmm', 'mmmmm', 'mmmmmm', 'mnth', 'mnths', 'mo', 'moan', 'mob', 'mobile', 'mobilesdirect', 'mobileupd', 'mobno', 'moby', 'mode', 'model', 'module', 'moji', 'mojibiola', 'mokka', 'mom', 'moment', 'mon', 'monday', 'money', 'monkey', 'mono', 'month', 'monthly', 'mood', 'moon', 'moral', 'morefrmmob', 'morn', 'mornin', 'morning', 'moro', 'morow', 'morphine', 'morro', 'morrow', 'mother', 'motorola', 'mountain', 'mouth', 'moved', 'movie', 'movietrivia', 'moving', 'mp', 'mr', 'mrng', 'mrt', 'mrw', 'msg', 'msging', 'msgrcvd', 'msgrcvdhg', 'msn', 'mt', 'mtalk', 'mth', 'mths', 'mtmsg', 'mtmsgrcvd', 'mu', 'muah', 'mum', 'mummy', 'mumtaz', 'munsters', 'murder', 'murdered', 'murderer', 'music', 'musthu', 'muz', 'mystery', 'na', 'nag', 'nagar', 'nah', 'nahi', 'naked', 'nalla', 'named', 'nan', 'nanny', 'nap', 'nasdaq', 'nasty', 'nat', 'natalie', 'natalja', 'national', 'natural', 'nature', 'naughty', 'nb', 'nd', 'ne', 'near', 'nearly', 'necessarily', 'necessary', 'neck', 'necklace', 'ned', 'need', 'needed', 'neft', 'neighbor', 'neighbour', 'nervous', 'net', 'netcollex', 'network', 'networking', 'neva', 'new', 'neway', 'newest', 'news', 'ni', 'nic', 'nice', 'nichols', 'nigeria', 'night', 'nimya', 'nit', 'nite', 'nitros', 'noe', 'nok', 'nokia', 'nokias', 'noline', 'noon', 'nope', 'norm', 'normal', 'normally', 'northampton', 'note', 'nothin', 'notice', 'notxt', 'noun', 'nowadays', 'nt', 'ntt', 'ntwk', 'nu', 'num', 'number', 'nurungu', 'nuther', 'nvm', 'nw', 'nxt', 'ny', 'nyc', 'nydc', 'nyt', 'obviously', 'occupy', 'odi', 'offer', 'office', 'official', 'officially', 'ofice', 'oh', 'oi', 'oic', 'oil', 'ok', 'okay', 'okey', 'okie', 'ola', 'old', 'omg', 'omw', 'oni', 'onion', 'online', 'onwards', 'oooh', 'oops', 'open', 'opening', 'operator', 'opinion', 'opportunity', 'opt', 'option', 'optout', 'orange', 'orchard', 'order', 'ordered', 'oredi', 'oreo', 'orig', 'original', 'oru', 'oso', 'otside', 'outage', 'outside', 'outstanding', 'outta', 'ovulation', 'ow', 'owns', 'oz', 'pa', 'pack', 'package', 'page', 'paid', 'pain', 'painful', 'painting', 'pale', 'pan', 'pandy', 'panic', 'pap', 'paper', 'paperwork', 'paragon', 'parco', 'parent', 'paris', 'park', 'parked', 'parking', 'partner', 'partnership', 'party', 'pas', 'passed', 'passionate', 'password', 'past', 'path', 'pattern', 'patty', 'pay', 'payed', 'payee', 'paying', 'payment', 'payoh', 'pc', 'peace', 'peaceful', 'peak', 'pee', 'pen', 'pending', 'penis', 'penny', 'people', 'percent', 'perfect', 'period', 'permission', 'person', 'personal', 'personality', 'perwksub', 'pete', 'petey', 'petrol', 'pg', 'ph', 'philosophy', 'phne', 'phoenix', 'phone', 'phoned', 'photo', 'php', 'pic', 'pick', 'picked', 'picking', 'pickle', 'picsfree', 'picture', 'pie', 'piece', 'pig', 'pilate', 'pimple', 'pin', 'pink', 'piss', 'pissed', 'pix', 'pizza', 'place', 'placement', 'plan', 'plane', 'planet', 'planned', 'planning', 'play', 'played', 'player', 'playing', 'plaza', 'pleased', 'pleasure', 'plenty', 'plm', 'pls', 'plus', 'plz', 'pm', 'po', 'pobox', 'pocketbabe', 'pod', 'poem', 'point', 'poker', 'pole', 'police', 'politician', 'polo', 'poly', 'polyh', 'polyph', 'polyphonic', 'polys', 'pongal', 'pool', 'poop', 'poor', 'pop', 'popcorn', 'popped', 'porn', 'position', 'possession', 'possible', 'post', 'postcard', 'postcode', 'posted', 'potato', 'potential', 'potter', 'pouch', 'pound', 'pours', 'pout', 'power', 'pp', 'ppermesssubscription', 'ppl', 'pple', 'ppm', 'ppmx', 'ppw', 'prabha', 'practical', 'practice', 'practicing', 'pray', 'praying', 'pre', 'prefer', 'preferably', 'prem', 'premier', 'premium', 'prepaid', 'prepare', 'prepared', 'prepayment', 'prescription', 'present', 'press', 'pretty', 'previous', 'previously', 'prey', 'price', 'pride', 'prince', 'princess', 'print', 'printed', 'priscilla', 'privacy', 'private', 'prize', 'pro', 'prob', 'probably', 'problem', 'probs', 'process', 'processed', 'prof', 'professor', 'profile', 'profit', 'program', 'project', 'prolly', 'promise', 'promo', 'prompt', 'proof', 'properly', 'property', 'propose', 'propsd', 'prospect', 'protect', 'prove', 'proverb', 'provided', 'pt', 'ptbo', 'pub', 'public', 'pull', 'purchase', 'purity', 'purpose', 'purse', 'push', 'pussy', 'puttin', 'putting', 'pw', 'px', 'qatar', 'qp', 'qu', 'quality', 'queen', 'ques', 'question', 'questioned', 'quick', 'quickly', 'quiet', 'quit', 'quite', 'quiz', 'quote', 'quoting', 'qxj', 'racing', 'radio', 'raed', 'rael', 'railway', 'rain', 'raining', 'raise', 'raj', 'raji', 'rakhesh', 'rally', 'ran', 'random', 'randomly', 'randy', 'rang', 'range', 'ranjith', 'rate', 'ray', 'rcv', 'rcvd', 'rd', 'reach', 'reached', 'reaching', 'reaction', 'read', 'reader', 'reading', 'ready', 'real', 'realise', 'reality', 'realize', 'realized', 'really', 'realy', 'reason', 'reasonable', 'reboot', 'rec', 'recd', 'receipt', 'receive', 'receivea', 'received', 'receiving', 'recent', 'recently', 'recession', 'recharge', 'reckon', 'recognise', 'record', 'recovery', 'red', 'redeemed', 'reduce', 'ref', 'reference', 'refilled', 'refused', 'reg', 'regard', 'regarding', 'register', 'registered', 'regret', 'regular', 'relation', 'relative', 'relax', 'released', 'rem', 'remain', 'remains', 'remember', 'remembered', 'remembr', 'remind', 'reminder', 'reminding', 'removal', 'remove', 'removed', 'renewal', 'rent', 'rental', 'rentl', 'repair', 'repeat', 'replace', 'replacement', 'replied', 'reply', 'replying', 'report', 'representative', 'request', 'research', 'reserve', 'respect', 'respectful', 'responce', 'respond', 'responding', 'response', 'responsibility', 'rest', 'restaurant', 'result', 'resume', 'retrieve', 'return', 'returned', 'reveal', 'revealed', 'reverse', 'review', 'revision', 'reward', 'rewarding', 'rg', 'rgds', 'rhythm', 'rice', 'rich', 'ride', 'right', 'rightly', 'ring', 'ringtone', 'ringtoneking', 'ringtones', 'risk', 'rite', 'river', 'road', 'roast', 'rock', 'rofl', 'roger', 'role', 'romantic', 'ron', 'room', 'roommate', 'rose', 'round', 'row', 'royal', 'rply', 'rr', 'rstm', 'ru', 'rub', 'rude', 'ruin', 'ruining', 'rule', 'rum', 'rumour', 'run', 'running', 'rush', 'rw', 'ryan', 'sac', 'sachin', 'sacrifice', 'sad', 'sae', 'safe', 'said', 'sake', 'salam', 'salary', 'sale', 'salon', 'sam', 'santa', 'sar', 'sarasota', 'sarcasm', 'sarcastic', 'sary', 'sat', 'sathya', 'satisfied', 'satisfy', 'saturday', 'saucy', 'savamob', 'save', 'saved', 'saw', 'say', 'saying', 'scared', 'scary', 'sch', 'schedule', 'school', 'science', 'scold', 'score', 'scoring', 'scotch', 'scotland', 'scotsman', 'scream', 'screamed', 'screaming', 'screen', 'scrounge', 'sd', 'se', 'sea', 'search', 'searching', 'season', 'seat', 'sec', 'second', 'secret', 'secretary', 'secretly', 'section', 'sed', 'seed', 'seeing', 'seen', 'select', 'selected', 'selection', 'self', 'selfish', 'sell', 'selling', 'sem', 'semester', 'sen', 'send', 'sender', 'sending', 'sends', 'sense', 'sensitive', 'sent', 'sentence', 'senthil', 'sept', 'series', 'seriously', 'service', 'serving', 'set', 'setting', 'settle', 'settled', 'seven', 'sex', 'sexy', 'sh', 'sha', 'shagged', 'shahjahan', 'shall', 'shame', 'shampain', 'share', 'shared', 'sharing', 'shd', 'sheet', 'sheffield', 'shelf', 'shesil', 'shijas', 'shining', 'ship', 'shipped', 'shipping', 'shirt', 'shit', 'shitload', 'shld', 'shock', 'shocking', 'shoe', 'shoot', 'shop', 'shoppin', 'shopping', 'shore', 'short', 'shortage', 'shorter', 'shortly', 'shot', 'shouldn', 'shouted', 'shoving', 'shower', 'showing', 'shracomorsglsuplt', 'shu', 'shuhui', 'shut', 'shy', 'si', 'sian', 'sib', 'sick', 'sigh', 'sight', 'sign', 'signing', 'silence', 'silent', 'silently', 'silver', 'sim', 'simple', 'simpler', 'simply', 'sinco', 'sing', 'singing', 'single', 'sip', 'sipix', 'sir', 'sister', 'sit', 'site', 'sitll', 'sitting', 'situation', 'siva', 'size', 'sk', 'skilgme', 'skillgame', 'skip', 'sky', 'skype', 'skyped', 'slap', 'slave', 'sleep', 'sleepin', 'sleeping', 'slept', 'slice', 'slipper', 'slow', 'slowly', 'sm', 'small', 'smart', 'smile', 'smiling', 'smoke', 'smoking', 'smth', 'sn', 'snake', 'snow', 'social', 'sofa', 'soft', 'software', 'sol', 'solve', 'somebody', 'somethin', 'song', 'sony', 'sonyericsson', 'soon', 'sooner', 'sore', 'sorrow', 'sorry', 'sort', 'sorted', 'sorting', 'sory', 'soryda', 'sound', 'soup', 'source', 'south', 'sp', 'space', 'spanish', 'spare', 'speak', 'special', 'specially', 'speechless', 'speed', 'spell', 'spend', 'spending', 'spent', 'spk', 'spl', 'spoke', 'spoken', 'spook', 'sport', 'spree', 'spring', 'sry', 'st', 'staff', 'stamp', 'stand', 'standard', 'standing', 'star', 'start', 'started', 'starting', 'starwars', 'statement', 'station', 'stay', 'staying', 'std', 'step', 'stock', 'stockport', 'stomach', 'stomp', 'stone', 'stop', 'stopped', 'stoptxt', 'store', 'storming', 'story', 'str', 'straight', 'stranger', 'street', 'stress', 'stretch', 'strike', 'strip', 'strong', 'stuck', 'student', 'study', 'studying', 'stuff', 'stupid', 'style', 'stylish', 'sub', 'subpoly', 'subscribe', 'subscribed', 'subscriber', 'subscription', 'successful', 'successfully', 'suck', 'sugar', 'suggest', 'suite', 'sum', 'summer', 'sun', 'sunday', 'sunny', 'sunshine', 'suntec', 'sup', 'super', 'superb', 'superior', 'supervisor', 'supply', 'support', 'supposed', 'suprman', 'sura', 'sure', 'surely', 'surfing', 'surprise', 'surprised', 'sw', 'sweet', 'sweetest', 'swimming', 'swing', 'switch', 'swt', 'swtheart', 'symbol', 'ta', 'table', 'tablet', 'taken', 'takin', 'taking', 'talent', 'talk', 'talking', 'tampa', 'tape', 'tariff', 'tat', 'taunton', 'taylor', 'tb', 'tc', 'tcr', 'tea', 'teach', 'teacher', 'team', 'tear', 'tease', 'teasing', 'technical', 'teeth', 'tel', 'tell', 'telling', 'telphone', 'temp', 'temple', 'tenant', 'tenerife', 'term', 'terrible', 'tessy', 'test', 'text', 'textcomp', 'texted', 'texting', 'textoperator', 'textpod', 'tf', 'th', 'thangam', 'thank', 'thanks', 'thanksgiving', 'thanx', 'thats', 'theatre', 'themob', 'theory', 'thing', 'think', 'thinkin', 'thinking', 'thk', 'thm', 'thnk', 'tho', 'thought', 'threat', 'throat', 'throw', 'tht', 'thts', 'thurs', 'thursday', 'ti', 'tick', 'ticket', 'tihs', 'til', 'till', 'time', 'timing', 'tired', 'tirupur', 'title', 'tkts', 'tlp', 'tm', 'tmr', 'tncs', 'toa', 'toclaim', 'today', 'tog', 'told', 'toll', 'tom', 'tomarrow', 'tomo', 'tomorrow', 'tone', 'tonight', 'tonite', 'took', 'torch', 'tot', 'total', 'totally', 'touch', 'touched', 'tough', 'tour', 'town', 'track', 'trade', 'traffic', 'train', 'training', 'transaction', 'transfer', 'transfered', 'travel', 'treat', 'treated', 'tree', 'tried', 'trip', 'trouble', 'truck', 'true', 'truffle', 'truly', 'trust', 'truth', 'try', 'trying', 'tsandcs', 'tscs', 'tsunami', 'tt', 'ttyl', 'tues', 'tuesday', 'tuition', 'turn', 'tv', 'twice', 'txt', 'txtauction', 'txtin', 'txting', 'txts', 'tyler', 'type', 'tyrone', 'ubi', 'ugh', 'uk', 'umma', 'ummmmmaah', 'unable', 'uncle', 'understand', 'understanding', 'understood', 'uni', 'unique', 'university', 'unless', 'unlimited', 'unredeemed', 'unsold', 'unsub', 'unsubscribe', 'update', 'upgrade', 'upload', 'upset', 'upto', 'ur', 'urawinner', 'ure', 'urgent', 'urgently', 'urgnt', 'url', 'urn', 'urself', 'usc', 'use', 'used', 'user', 'usf', 'using', 'usual', 'usually', 'uz', 'vaazhthukkal', 'vale', 'valentine', 'valid', 'valuable', 'value', 'valued', 'various', 'vary', 'vava', 'vday', 've', 'vega', 'vegetable', 'verified', 'verify', 'version', 'vettam', 'vewy', 'vid', 'video', 'videochat', 'videophones', 'vijay', 'vikky', 'village', 'violated', 'violence', 'violet', 'vip', 'virgin', 'visionsms', 'visit', 'visitor', 'viva', 'vivek', 'vl', 'voda', 'vodafone', 'vodka', 'voice', 'voicemail', 'vomit', 'vomiting', 'vote', 'voucher', 'vry', 'vth', 'vu', 'wa', 'wah', 'waheed', 'waht', 'wait', 'waited', 'waitin', 'waiting', 'wake', 'waking', 'wale', 'walk', 'walked', 'walking', 'wall', 'wallpaper', 'walmart', 'wan', 'wana', 'want', 'wanted', 'wanting', 'wap', 'warm', 'warner', 'warning', 'warranty', 'wasn', 'waste', 'wasted', 'wat', 'watch', 'watching', 'water', 'watever', 'wating', 'wats', 'wave', 'waxsto', 'way', 'wb', 'wc', 'weak', 'weakness', 'wear', 'wearing', 'weather', 'web', 'website', 'wed', 'wedding', 'wednesday', 'wee', 'weed', 'week', 'weekend', 'weekly', 'weigh', 'weight', 'weird', 'weirdest', 'welcome', 'welp', 'wen', 'went', 'wer', 'wesley', 'west', 'westlife', 'wet', 'whats', 'whatsup', 'whenevr', 'white', 'whn', 'whr', 'wicklow', 'wid', 'widelive', 'wif', 'wife', 'wifi', 'wihtuot', 'wil', 'willing', 'win', 'winaweek', 'winawk', 'wind', 'window', 'wine', 'winner', 'winning', 'wipro', 'wisdom', 'wise', 'wish', 'wishin', 'wishing', 'wiskey', 'wit', 'wiv', 'wk', 'wkend', 'wkent', 'wkg', 'wkly', 'wks', 'wld', 'wml', 'wn', 'wnt', 'wo', 'woke', 'woken', 'woman', 'won', 'wonder', 'wonderful', 'wondering', 'wont', 'woot', 'word', 'work', 'workin', 'working', 'world', 'worried', 'worry', 'worse', 'worst', 'worth', 'wot', 'woulda', 'wouldn', 'wow', 'wp', 'wq', 'wrc', 'write', 'wrk', 'wrnog', 'wrong', 'wrote', 'wt', 'wtf', 'wu', 'wud', 'wuld', 'wun', 'www', 'wx', 'wylie', 'xam', 'xavier', 'xchat', 'xh', 'xin', 'xmas', 'xn', 'xuhui', 'xx', 'xxx', 'xxxmobilemovieclub', 'xxxx', 'xxxxx', 'xxxxxx', 'xxxxxxx', 'xxxxxxxxx', 'xy', 'ya', 'yahoo', 'yan', 'yar', 'yarasu', 'yay', 'yck', 'yeah', 'year', 'yeh', 'yelling', 'yellow', 'yep', 'yer', 'yes', 'yest', 'yesterday', 'yetunde', 'yf', 'yijue', 'ym', 'yo', 'yoga', 'yogasana', 'yor', 'youre', 'yr', 'yummy', 'yun', 'yunny', 'yuo', 'yup', 'zed', 'zindgi', 'zoe']\n"
     ]
    }
   ],
   "source": [
    "#We make bag of word it is including number of all word's info\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "max_features = 3000 #We use the most common word\n",
    "count_vectorizer = CountVectorizer(max_features = max_features, stop_words = \"english\")\n",
    "sparce_matrix = count_vectorizer.fit_transform(description_list).toarray()\n",
    "print(\"the most using {} words: {}\".format(max_features,count_vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We separate our data is train and test\n",
    "y = data.iloc[:,0].values   # male or female classes\n",
    "x = sparce_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is a statistical model that in its basic form uses a logistic function to model a binary dependent variable, although many more complex extensions exist. In regression analysis, logistic regression (or logit regression) is estimating the parameters of a logistic model (a form of binary regression)\n",
    "\n",
    "Logistic regression is the appropriate regression analysis to conduct when the dependent variable is binary. Logistic regression is used to describe data and to explain the relationship between one dependent binary variable and one or more nominal, ordinal, interval or ratio-level independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our accuracy is: 0.9767025089605734\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(max_iter = 200)\n",
    "lr.fit(x_train,y_train)\n",
    "print(\"our accuracy is: {}\".format(lr.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# create an instance\n",
    "count_vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the vectorizer with data\n",
    "count_vect.fit(data)\n",
    "# convert text to vectors\n",
    "X = count_vect.transform(data.Message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "y = le.fit_transform(data.Category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(criterion='gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1393,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.\n",
    "\n",
    "The random forest is a classification algorithm consisting of many decisions trees. It uses bagging and feature randomness when building each individual tree to try to create an uncorrelated forest of trees whose prediction by committee is more accurate than that of any individual tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=5, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
